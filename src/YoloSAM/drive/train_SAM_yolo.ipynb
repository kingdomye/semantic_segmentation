{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "930f8227-54d7-4c70-9b35-9d928bd585c0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.12/site-packages/albumentations/check_version.py:147: UserWarning: Error fetching version info The read operation timed out\n",
      "  data = fetch_version_info()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… é”å®šæœ€æ–° YOLO æƒé‡: /root/task/src/YoloSAM/drive/runs/yolo_vessel_detection3/weights/best.pt\n",
      "æ­£åœ¨åŠ è½½æ•°æ®é›†...\n",
      "Scanning images in ../../../datasets/DRIVE/train/images...\n",
      "âœ… Successfully loaded 100 image-mask pairs.\n",
      "Removed 0 empty masks\n",
      "Loaded 100 images and masks\n",
      "Scanning images in ../../../datasets/DRIVE/val/images...\n",
      "âœ… Successfully loaded 20 image-mask pairs.\n",
      "Removed 0 empty masks\n",
      "Loaded 20 images and masks\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mwandb\u001B[0m: \u001B[32m\u001B[41mERROR\u001B[0m Failed to detect the name of this notebook. You can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "åˆå§‹åŒ– Trainer...\n",
      "Load SAM model from  /root/task/checkpoints/sam_vit_b_01ec64.pth\n",
      "ğŸš€ å¼€å§‹ End-to-End è®­ç»ƒï¼(YOLO: best.pt)\n",
      "Starting training for 20 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:   0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== SAMè¾“å…¥éªŒè¯ =====\n",
      "è¾“å…¥å›¾åƒå½¢çŠ¶: torch.Size([2, 3, 1024, 1024])\n",
      "è¾“å…¥maskæ±‚å’Œ: 137106.0\n",
      "è¾“å…¥boxeså½¢çŠ¶: torch.Size([2, 1, 4]), å€¼: tensor([[[   1.2794,  135.0325,  265.1646,  541.1417]],\n",
      "\n",
      "        [[ 730.5130,   94.9428, 1019.9362,  560.1650]]], device='cuda:0')\n",
      "é¢„æµ‹æ©ç (æ¦‚ç‡)æ±‚å’Œ: 134280.90625, äºŒå€¼åŒ–åæ±‚å’Œ: 102454.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [00:27<00:00,  1.79it/s, loss=0.243]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: Train Loss = 0.4683, Train Dice = 0.1599\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:03<00:00,  2.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: Validation Loss = 0.2606, Validation Dice = 0.6175\n",
      "Saved best model checkpoint to /root/autodl-tmp/run_25/best_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [00:27<00:00,  1.84it/s, loss=0.158]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss = 0.1902, Train Dice = 0.6933\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:03<00:00,  2.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Validation Loss = 0.1492, Validation Dice = 0.7725\n",
      "Saved best model checkpoint to /root/autodl-tmp/run_25/best_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [00:26<00:00,  1.86it/s, loss=0.177]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Train Loss = 0.1779, Train Dice = 0.7048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:03<00:00,  2.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Validation Loss = 0.1982, Validation Dice = 0.6712\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [00:26<00:00,  1.87it/s, loss=0.162]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Train Loss = 0.1678, Train Dice = 0.7180\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:03<00:00,  2.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Validation Loss = 0.1529, Validation Dice = 0.7684\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [00:26<00:00,  1.87it/s, loss=0.174]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: Train Loss = 0.1638, Train Dice = 0.7215\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:03<00:00,  2.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: Validation Loss = 0.1503, Validation Dice = 0.7595\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [00:26<00:00,  1.86it/s, loss=0.125]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: Train Loss = 0.1615, Train Dice = 0.7264\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:03<00:00,  2.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: Validation Loss = 0.1466, Validation Dice = 0.7601\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [00:26<00:00,  1.86it/s, loss=0.138]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: Train Loss = 0.1556, Train Dice = 0.7330\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:03<00:00,  2.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: Validation Loss = 0.1499, Validation Dice = 0.7512\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [00:26<00:00,  1.86it/s, loss=0.162]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: Train Loss = 0.1532, Train Dice = 0.7360\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:03<00:00,  2.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: Validation Loss = 0.1440, Validation Dice = 0.7634\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [00:26<00:00,  1.86it/s, loss=0.139]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: Train Loss = 0.1513, Train Dice = 0.7383\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:03<00:00,  2.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: Validation Loss = 0.1584, Validation Dice = 0.7360\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [00:27<00:00,  1.85it/s, loss=0.194]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: Train Loss = 0.1503, Train Dice = 0.7409\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:03<00:00,  2.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: Validation Loss = 0.1425, Validation Dice = 0.7599\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [00:27<00:00,  1.84it/s, loss=0.125]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: Train Loss = 0.1476, Train Dice = 0.7456\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:03<00:00,  2.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: Validation Loss = 0.1606, Validation Dice = 0.7220\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [00:27<00:00,  1.85it/s, loss=0.151]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11: Train Loss = 0.1467, Train Dice = 0.7448\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:03<00:00,  2.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11: Validation Loss = 0.1329, Validation Dice = 0.7830\n",
      "Saved best model checkpoint to /root/autodl-tmp/run_25/best_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [00:26<00:00,  1.91it/s, loss=0.149]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12: Train Loss = 0.1472, Train Dice = 0.7451\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:03<00:00,  2.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12: Validation Loss = 0.1524, Validation Dice = 0.7425\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [00:26<00:00,  1.85it/s, loss=0.137]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13: Train Loss = 0.1455, Train Dice = 0.7467\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:03<00:00,  2.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13: Validation Loss = 0.1372, Validation Dice = 0.7739\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 43/50 [00:23<00:03,  1.83it/s, loss=0.107]"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import glob\n",
    "\n",
    "paths_to_add = [\n",
    "    '/root',         \n",
    "    '/root/task'   \n",
    "]\n",
    "\n",
    "for p in paths_to_add:\n",
    "    if p not in sys.path:\n",
    "        sys.path.append(p)\n",
    "\n",
    "from src.YoloSAM.scripts.train_sam import TrainSAM\n",
    "from src.YoloSAM.utils.dataset import SAMDataset\n",
    "from src.YoloSAM.utils.config import SAMFinetuneConfig, SAMDatasetConfig\n",
    "\n",
    "custom_yolo_path = \"/root/task/src/YoloSAM/drive/runs/yolo_vessel_detection3/weights/best.pt\"\n",
    "\n",
    "# ==================================================\n",
    "# 2. é…ç½® SAM å¾®è°ƒå‚æ•°\n",
    "# ==================================================\n",
    "finetune_config = SAMFinetuneConfig(\n",
    "    device='cuda',\n",
    "    wandb_project='SAM_finetune',\n",
    "    wandb_name='Real_YoloSAM_Run',\n",
    "    model_type='vit_b',\n",
    "    sam_path='/root/task/checkpoints/sam_vit_b_01ec64.pth',\n",
    "\n",
    "    num_epochs=20,  \n",
    "    \n",
    "    batch_size=2,\n",
    "    learning_rate=5e-5,\n",
    "    weight_decay=1e-4,\n",
    "    lambda_bce=0.5,\n",
    "    lambda_kl=0.0,\n",
    "    sigma=1,\n",
    "    wandb_mode='disabled',\n",
    "    num_workers=0\n",
    ")\n",
    "\n",
    "train_dataset_config = SAMDatasetConfig(\n",
    "    dataset_path='../../../datasets/DRIVE/train',\n",
    "    remove_nonscar=True,\n",
    "    sample_size=None,\n",
    "    \n",
    "    # å…³é—­ GT æç¤ºï¼Œå®Œå…¨ä¾èµ– YOLO\n",
    "    point_prompt=False, \n",
    "    box_prompt=False, \n",
    "    \n",
    "    # å¼€å¯ YOLO æç¤º\n",
    "    yolo_prompt=True, \n",
    "\n",
    "    yolo_model_path=custom_yolo_path, \n",
    "\n",
    "    yolo_conf_threshold=0.01, \n",
    "    yolo_iou_threshold=0.5,\n",
    "    yolo_imgsz=640,\n",
    "    \n",
    "    image_size=1024,\n",
    "    train=True,\n",
    "    \n",
    "    # å¼€å¯å¢å¼ºï¼Œé˜²æ­¢è¿‡æ‹Ÿåˆ\n",
    "    enable_direction_aug=True, \n",
    "    enable_size_aug=True \n",
    ")\n",
    "\n",
    "val_dataset_config = SAMDatasetConfig(\n",
    "    dataset_path='../../../datasets/DRIVE/val',\n",
    "    remove_nonscar=True,\n",
    "    sample_size=None,\n",
    "    point_prompt=False,\n",
    "    box_prompt=False,\n",
    "    yolo_prompt=True,\n",
    "    \n",
    "    # éªŒè¯é›†ä¹Ÿè¦ç”¨åŒä¸€ä¸ª YOLO\n",
    "    yolo_model_path=custom_yolo_path,\n",
    "\n",
    "    yolo_conf_threshold=0.01,\n",
    "    yolo_iou_threshold=0.5,\n",
    "    yolo_imgsz=640,\n",
    "    \n",
    "    image_size=1024,\n",
    "    train=False\n",
    ")\n",
    "\n",
    "print(\"æ­£åœ¨åŠ è½½æ•°æ®é›†...\")\n",
    "train_dataset = SAMDataset(train_dataset_config.__dict__)\n",
    "val_dataset = SAMDataset(val_dataset_config.__dict__)\n",
    "\n",
    "print(\"åˆå§‹åŒ– Trainer...\")\n",
    "trainer = TrainSAM(finetune_config, train_dataset, val_dataset)\n",
    "current_output_dir = trainer.output_dir\n",
    "os.makedirs(current_output_dir, exist_ok=True)\n",
    "\n",
    "trainer.train(finetune_config.num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "349c613e-ffb1-486a-b965-5eef8948dcc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import glob\n",
    "import cv2\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "paths_to_add = [\n",
    "    '/root',         \n",
    "    '/root/task'   \n",
    "]\n",
    "\n",
    "for p in paths_to_add:\n",
    "    if p not in sys.path:\n",
    "        sys.path.append(p)\n",
    "\n",
    "# æ–°å¢SAMæ¨ç†æ‰€éœ€ä¾èµ–\n",
    "from segment_anything import sam_model_registry, SamPredictor\n",
    "from ultralytics import YOLO\n",
    "import torch\n",
    "\n",
    "# ==================================================\n",
    "# 1. è‡ªåŠ¨å¯»æ‰¾åˆšæ‰è®­ç»ƒæœ€å¥½çš„ YOLO æ¨¡å‹\n",
    "# ==================================================\n",
    "# æœç´¢ runs æ–‡ä»¶å¤¹ä¸‹æ‰€æœ‰çš„ best.pt\n",
    "possible_weights = glob.glob(\"/root/task/**/runs/**/weights/best.pt\", recursive=True)\n",
    "\n",
    "if not possible_weights:\n",
    "    raise FileNotFoundError(\"âŒ æ‰¾ä¸åˆ°è®­ç»ƒå¥½çš„ YOLO æ¨¡å‹ï¼è¯·ç¡®è®¤ä¹‹å‰çš„ YOLO è®­ç»ƒå·²å®Œæˆã€‚\")\n",
    "\n",
    "# æŒ‰ä¿®æ”¹æ—¶é—´æ’åºï¼Œå–æœ€æ–°çš„ä¸€ä¸ª\n",
    "custom_yolo_path = \"/root/task/src/YoloSAM/drive/runs/yolo_vessel_detection2/weights/best.pt\"\n",
    "print(f\"âœ… é”å®šæœ€æ–° YOLO æƒé‡: {custom_yolo_path}\")\n",
    "\n",
    "# ==================================================\n",
    "# 2. åˆå§‹åŒ– YOLO æ¨¡å‹å’Œ SAM æ¨¡å‹ï¼ˆæ ¸å¿ƒä¿®æ”¹ï¼‰\n",
    "# ==================================================\n",
    "# åŠ è½½YOLOè¡€ç®¡æ£€æµ‹æ¨¡å‹\n",
    "yolo_model = YOLO(custom_yolo_path)\n",
    "yolo_model.to('cuda')\n",
    "\n",
    "# åŠ è½½SAMæ¨¡å‹ï¼ˆvit_bï¼Œé€‚é…æ˜¾å­˜ï¼‰\n",
    "sam_checkpoint = '/root/task/checkpoints/sam_vit_b_01ec64.pth'\n",
    "model_type = 'vit_b'\n",
    "device = 'cuda'\n",
    "\n",
    "sam = sam_model_registry[model_type](checkpoint=sam_checkpoint)\n",
    "sam.to(device=device)\n",
    "predictor = SamPredictor(sam)\n",
    "\n",
    "# ==================================================\n",
    "# 3. å®šä¹‰è¡€ç®¡åˆ‡å‰²æ ¸å¿ƒå‡½æ•°\n",
    "# ==================================================\n",
    "def segment_vessel_with_yolo_sam(image_path, output_dir):\n",
    "    \"\"\"\n",
    "    ç»“åˆYOLOæ£€æµ‹æ¡†å’ŒSAMåˆ‡å‰²è¡€ç®¡\n",
    "    :param image_path: è¾“å…¥çœ¼åº•å›¾è·¯å¾„\n",
    "    :param output_dir: åˆ†å‰²ç»“æœä¿å­˜ç›®å½•\n",
    "    \"\"\"\n",
    "    # åˆ›å»ºè¾“å‡ºç›®å½•\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    image_name = Path(image_path).stem\n",
    "    \n",
    "    # Step 1: YOLOæ£€æµ‹è¡€ç®¡æ¡†\n",
    "    results = yolo_model.predict(\n",
    "        source=image_path,\n",
    "        conf=0.5,  # è¿‡æ»¤ä½ç½®ä¿¡åº¦æ¡†ï¼ˆç”¨è®­ç»ƒåçš„é«˜é˜ˆå€¼ï¼‰\n",
    "        iou=0.5,\n",
    "        imgsz=640,\n",
    "        device='cuda',\n",
    "        verbose=False\n",
    "    )\n",
    "    \n",
    "    # æå–YOLOæ£€æµ‹æ¡†ï¼ˆæ ¼å¼ï¼šxyxyï¼‰\n",
    "    boxes = []\n",
    "    for r in results:\n",
    "        for box in r.boxes:\n",
    "            if box.conf > 0.5:  # åªä¿ç•™é«˜ç½®ä¿¡åº¦æ¡†\n",
    "                xyxy = box.xyxy.cpu().numpy()[0]  # (x1, y1, x2, y2)\n",
    "                boxes.append(xyxy)\n",
    "    \n",
    "    if not boxes:\n",
    "        print(f\"âš ï¸ {image_name} æœªæ£€æµ‹åˆ°è¡€ç®¡æ¡†ï¼Œè·³è¿‡\")\n",
    "        return\n",
    "    \n",
    "    # Step 2: SAMåˆ†å‰²\n",
    "    # è¯»å–å›¾åƒ\n",
    "    image = cv2.imread(image_path)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # è®¾ç½®SAMå›¾åƒ\n",
    "    predictor.set_image(image)\n",
    "    \n",
    "    # è½¬æ¢æ¡†æ ¼å¼ä¸ºSAMæ‰€éœ€ï¼ˆxyxy -> å½’ä¸€åŒ–ï¼‰\n",
    "    input_boxes = torch.tensor(boxes, device=predictor.device)\n",
    "    transformed_boxes = predictor.transform.apply_boxes_torch(input_boxes, image.shape[:2])\n",
    "    \n",
    "    # SAMæ¨ç†\n",
    "    masks, _, _ = predictor.predict_torch(\n",
    "        point_coords=None,\n",
    "        point_labels=None,\n",
    "        boxes=transformed_boxes,\n",
    "        multimask_output=False,\n",
    "    )\n",
    "    \n",
    "    # Step 3: åˆå¹¶æ‰€æœ‰maskå¹¶ä¿å­˜\n",
    "    # åˆå¹¶maskï¼ˆå–å¹¶é›†ï¼‰\n",
    "    combined_mask = np.zeros(image.shape[:2], dtype=np.uint8)\n",
    "    for mask in masks:\n",
    "        mask_np = mask.cpu().numpy().squeeze()\n",
    "        combined_mask = np.maximum(combined_mask, mask_np.astype(np.uint8))\n",
    "    \n",
    "    # ä¿å­˜åˆ†å‰²ç»“æœ\n",
    "    # 1. äºŒå€¼mask\n",
    "    mask_path = os.path.join(output_dir, f\"{image_name}_vessel_mask.png\")\n",
    "    cv2.imwrite(mask_path, combined_mask * 255)  # 0->0, 1->255\n",
    "    \n",
    "    # 2. å åŠ å¯è§†åŒ–å›¾\n",
    "    vis_image = image.copy()\n",
    "    vis_image[combined_mask == 1] = [255, 0, 0]  # è¡€ç®¡åŒºåŸŸæ ‡çº¢\n",
    "    vis_image = cv2.cvtColor(vis_image, cv2.COLOR_RGB2BGR)\n",
    "    vis_path = os.path.join(output_dir, f\"{image_name}_vessel_vis.png\")\n",
    "    cv2.imwrite(vis_path, vis_image)\n",
    "    \n",
    "    print(f\"âœ… {image_name} è¡€ç®¡åˆ†å‰²å®Œæˆï¼Œç»“æœä¿å­˜è‡³ {output_dir}\")\n",
    "\n",
    "# ==================================================\n",
    "# 4. æ‰¹é‡å¤„ç†æ•°æ®é›†\n",
    "# ==================================================\n",
    "# é…ç½®æ•°æ®é›†è·¯å¾„\n",
    "dataset_dir = '../../../datasets/DRIVE/val/images'\n",
    "output_dir = '/root/task/src/YoloSAM/results/vessel_segmentation'\n",
    "\n",
    "# è·å–æ‰€æœ‰å›¾åƒ\n",
    "image_paths = glob.glob(os.path.join(dataset_dir, '*.tif')) + glob.glob(os.path.join(dataset_dir, '*.jpg'))\n",
    "\n",
    "# æ‰¹é‡åˆ†å‰²\n",
    "print(f\"\\nğŸš€ å¼€å§‹æ‰¹é‡åˆ†å‰²è¡€ç®¡ï¼Œå…± {len(image_paths)} å¼ å›¾åƒ\")\n",
    "for img_path in image_paths:\n",
    "    segment_vessel_with_yolo_sam(img_path, output_dir)\n",
    "\n",
    "# ==================================================\n",
    "# ï¼ˆå¯é€‰ï¼‰SAMå¾®è°ƒä»£ç ï¼ˆä¿ç•™åŸå¾®è°ƒé€»è¾‘ï¼ŒæŒ‰éœ€å¯ç”¨ï¼‰\n",
    "# ==================================================\n",
    "# from src.YoloSAM.scripts.train_sam import TrainSAM\n",
    "# from src.YoloSAM.utils.dataset import SAMDataset\n",
    "# from src.YoloSAM.utils.config import SAMFinetuneConfig, SAMDatasetConfig\n",
    "\n",
    "# finetune_config = SAMFinetuneConfig(\n",
    "#     device='cuda',\n",
    "#     wandb_project='SAM_finetune',\n",
    "#     wandb_name='Real_YoloSAM_Run',\n",
    "#     model_type='vit_b',\n",
    "#     sam_path='/root/task/checkpoints/sam_vit_b_01ec64.pth',\n",
    "#     num_epochs=20,  \n",
    "#     batch_size=2,\n",
    "#     learning_rate=1e-5,\n",
    "#     weight_decay=1e-4,\n",
    "#     lambda_bce=0.2,\n",
    "#     lambda_kl=0.2,\n",
    "#     sigma=1,\n",
    "#     wandb_mode='disabled',\n",
    "#     num_workers=0\n",
    "# )\n",
    "\n",
    "# train_dataset_config = SAMDatasetConfig(\n",
    "#     dataset_path='../../../datasets/DRIVE/train',\n",
    "#     remove_nonscar=True,\n",
    "#     sample_size=None,\n",
    "#     point_prompt=False, \n",
    "#     box_prompt=False, \n",
    "#     yolo_prompt=True, \n",
    "#     yolo_model_path=custom_yolo_path, \n",
    "#     yolo_conf_threshold=0.5,  # è°ƒé«˜é˜ˆå€¼ï¼Œåªç”¨é«˜ç½®ä¿¡åº¦æ¡†\n",
    "#     yolo_iou_threshold=0.5,\n",
    "#     yolo_imgsz=640,\n",
    "#     image_size=1024,\n",
    "#     train=True,\n",
    "#     enable_direction_aug=True, \n",
    "#     enable_size_aug=True \n",
    "# )\n",
    "\n",
    "# val_dataset_config = SAMDatasetConfig(\n",
    "#     dataset_path='../../../datasets/DRIVE/val',\n",
    "#     remove_nonscar=True,\n",
    "#     sample_size=None,\n",
    "#     point_prompt=False,\n",
    "#     box_prompt=False,\n",
    "#     yolo_prompt=True,\n",
    "#     yolo_model_path=custom_yolo_path,\n",
    "#     yolo_conf_threshold=0.5,\n",
    "#     yolo_iou_threshold=0.5,\n",
    "#     yolo_imgsz=640,\n",
    "#     image_size=1024,\n",
    "#     train=False\n",
    "# )\n",
    "\n",
    "# # å¾®è°ƒSAMï¼ˆæŒ‰éœ€å¯ç”¨ï¼‰\n",
    "# # print(\"æ­£åœ¨åŠ è½½æ•°æ®é›†...\")\n",
    "# # train_dataset = SAMDataset(train_dataset_config.__dict__)\n",
    "# # val_dataset = SAMDataset(val_dataset_config.__dict__)\n",
    "\n",
    "# # print(\"åˆå§‹åŒ– Trainer...\")\n",
    "# # trainer = TrainSAM(finetune_config, train_dataset, val_dataset)\n",
    "# # current_output_dir = trainer.output_dir\n",
    "# # os.makedirs(current_output_dir, exist_ok=True)\n",
    "\n",
    "# # print(f\"ğŸš€ å¼€å§‹ End-to-End è®­ç»ƒï¼(YOLO: {os.path.basename(custom_yolo_path)})\")\n",
    "# # trainer.train(finetune_config.num_epochs)\n",
    "\n",
    "print(\"\\nğŸ‰ æ‰€æœ‰å›¾åƒåˆ†å‰²å®Œæˆï¼ç»“æœä¿å­˜åœ¨ï¼š\", output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "576ba6a1-4c4c-4bf6-b4f0-9faf5eb849f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import glob\n",
    "import torch\n",
    "from dataclasses import asdict\n",
    "\n",
    "# è·¯å¾„é…ç½®\n",
    "paths_to_add = [\n",
    "    '/root',         \n",
    "    '/root/task'   \n",
    "]\n",
    "for p in paths_to_add:\n",
    "    if p not in sys.path:\n",
    "        sys.path.append(p)\n",
    "\n",
    "# å¯¼å…¥æ ¸å¿ƒæ¨¡å—ï¼ˆä¸¥æ ¼åŒ¹é…ä½ çš„TrainSAMæ¥å£ï¼‰\n",
    "from utils.config import SAMFinetuneConfig, SAMDatasetConfig\n",
    "from utils.dataset import SAMDataset\n",
    "from scripts.train_sam import TrainSAM  # å¯¼å…¥ä½ æä¾›çš„TrainSAMç±»\n",
    "\n",
    "# ==================================================\n",
    "# 1. é”å®šæœ€ä¼˜YOLOæ¨¡å‹ï¼ˆç”¨äºSAMè®­ç»ƒæç¤ºï¼‰\n",
    "# ==================================================\n",
    "# ä½ çš„é«˜ç²¾åº¦YOLOè¡€ç®¡æ£€æµ‹æ¨¡å‹è·¯å¾„\n",
    "CUSTOM_YOLO_PATH = \"/root/task/src/YoloSAM/drive/runs/yolo_vessel_detection2/weights/best.pt\"\n",
    "\n",
    "# éªŒè¯YOLOæ¨¡å‹å­˜åœ¨\n",
    "if not os.path.exists(CUSTOM_YOLO_PATH):\n",
    "    raise FileNotFoundError(f\"âŒ YOLOæ¨¡å‹ä¸å­˜åœ¨: {CUSTOM_YOLO_PATH}\")\n",
    "print(f\"âœ… å·²é”å®šYOLOæƒé‡: {CUSTOM_YOLO_PATH}\")\n",
    "\n",
    "# ==================================================\n",
    "# 2. é…ç½®SAMå¾®è°ƒå‚æ•°ï¼ˆä¸¥æ ¼åŒ¹é…SAMFinetuneConfigï¼‰\n",
    "# ==================================================\n",
    "finetune_config = SAMFinetuneConfig(\n",
    "    # åŸºç¡€è®¾å¤‡é…ç½®\n",
    "    device=\"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
    "    num_workers=0,  # é€‚é…CPUæ ¸å¿ƒæ•°\n",
    "    \n",
    "    # SAMæ¨¡å‹è·¯å¾„ï¼ˆvit_bå¹³è¡¡æ˜¾å­˜/ç²¾åº¦ï¼‰\n",
    "    sam_path=\"/root/task/checkpoints/sam_vit_b_01ec64.pth\",\n",
    "    checkpoint_path=None,  # ä»å¤´å¾®è°ƒï¼Œä¸åŠ è½½æ—§æƒé‡\n",
    "    model_type=\"vit_b\",\n",
    "    image_size=1024,\n",
    "    \n",
    "    # è®­ç»ƒæ ¸å¿ƒå‚æ•°ï¼ˆè¡€ç®¡åˆ†å‰²ä¼˜åŒ–ï¼‰\n",
    "    batch_size=2,          # RTX5090 32Gå¯è®¾ä¸º2ï¼Œvit_héœ€è®¾ä¸º1\n",
    "    num_epochs=50,         # å»¶é•¿è®­ç»ƒè½®æ•°ï¼Œå……åˆ†å­¦ä¹ è¡€ç®¡ç‰¹å¾\n",
    "    \n",
    "    # æŸå¤±å‡½æ•°ï¼ˆé€‚é…è¡€ç®¡äºŒåˆ†ç±»ï¼‰\n",
    "    lambda_bce=0.5,        # æå‡BCEæƒé‡ï¼ˆèšç„¦è¡€ç®¡åˆ†å‰²ï¼‰\n",
    "    lambda_kl=0.1,         # é™ä½KLæ•£åº¦ï¼ˆå‡å°‘æç¤ºåŒ¹é…æƒé‡ï¼‰\n",
    "    sigma=2.0,             # å¢å¤§sigmaï¼Œè®©maskæ›´å¹³æ»‘ï¼ˆé€‚é…ç»†é•¿è¡€ç®¡ï¼‰\n",
    "    \n",
    "    # ä¼˜åŒ–å™¨å‚æ•°ï¼ˆSAMå¾®è°ƒéœ€å°å­¦ä¹ ç‡ï¼‰\n",
    "    learning_rate=5e-6,    # è¿œä½äºé»˜è®¤å€¼ï¼Œé¿å…è¿‡æ‹Ÿåˆ\n",
    "    weight_decay=1e-4,\n",
    "    \n",
    "    # Wandbé…ç½®ï¼ˆå…³é—­æ—¥å¿—ï¼‰\n",
    "    wandb_project=\"SAM-Vessel-Finetune\",\n",
    "    wandb_name=\"DRIVE-YOLO-SAM-VitB\",\n",
    "    wandb_mode=\"disabled\"\n",
    ")\n",
    "\n",
    "# ==================================================\n",
    "# 3. é…ç½®æ•°æ®é›†ï¼ˆä¸¥æ ¼åŒ¹é…SAMDatasetConfigï¼‰\n",
    "# ==================================================\n",
    "def build_dataset_config(is_train: bool) -> SAMDatasetConfig:\n",
    "    \"\"\"æ„å»ºè®­ç»ƒ/éªŒè¯æ•°æ®é›†é…ç½®ï¼ˆä»…ç”¨YOLOæ¡†ä½œä¸ºæç¤ºï¼‰\"\"\"\n",
    "    return SAMDatasetConfig(\n",
    "        # æ•°æ®é›†è·¯å¾„\n",
    "        dataset_path=f\"../../../datasets/DRIVE/{'train' if is_train else 'val'}\",\n",
    "        image_size=1024,\n",
    "        \n",
    "        # æ•°æ®å¢å¼ºå‚æ•°ï¼ˆé€‚é…çœ¼åº•å›¾ï¼‰\n",
    "        percentiles=(0.1, 99.9),\n",
    "        rotate_limit=15,\n",
    "        rotate_prob=0.5 if is_train else 0.0,  # éªŒè¯é›†å…³é—­æ—‹è½¬\n",
    "        scale_limit=0.1,\n",
    "        scale_prob=0.5 if is_train else 0.0,   # éªŒè¯é›†å…³é—­ç¼©æ”¾\n",
    "        horizontal_flip_prob=0.2 if is_train else 0.0,  # é™ä½ç¿»è½¬æ¦‚ç‡\n",
    "        gamma_prob=0.0,  # å…³é—­gammaå¢å¼ºï¼ˆä¿æŠ¤è¡€ç®¡ç‰¹å¾ï¼‰\n",
    "        gamma_limit=(80, 120),\n",
    "        \n",
    "        # è®­ç»ƒ/éªŒè¯æ ‡è¯†\n",
    "        train=is_train,\n",
    "        \n",
    "        # æ•°æ®è¿‡æ»¤ï¼ˆè¡€ç®¡æ— \"éç˜¢ç—•\"æ¦‚å¿µï¼Œå…³é—­è¿‡æ»¤ï¼‰\n",
    "        remove_nonscar=False,\n",
    "        \n",
    "        # æ ¸å¿ƒï¼šYOLOæç¤ºé…ç½®ï¼ˆå…³é—­å…¶ä»–æ‰€æœ‰æç¤ºï¼‰\n",
    "        yolo_prompt=True,                # å¯ç”¨YOLOæ¡†ä½œä¸ºå”¯ä¸€æç¤º\n",
    "        yolo_model_path=CUSTOM_YOLO_PATH, # ä½ çš„é«˜ç²¾åº¦YOLOæ¨¡å‹\n",
    "        yolo_conf_threshold=0.5,         # ä»…ç”¨é«˜ç½®ä¿¡åº¦YOLOæ¡†\n",
    "        yolo_iou_threshold=0.5,          # NMSè¿‡æ»¤é‡å æ¡†\n",
    "        yolo_imgsz=640,                  # ä¸YOLOè®­ç»ƒå°ºå¯¸ä¸€è‡´\n",
    "        \n",
    "        # å…³é—­å…¶ä»–æç¤ºï¼ˆä»…ä¿ç•™YOLOæ¡†ï¼‰\n",
    "        box_prompt=False,\n",
    "        enable_direction_aug=False,\n",
    "        enable_size_aug=False,\n",
    "        point_prompt=False,\n",
    "        num_points=3,\n",
    "        point_prompt_types=['positive'],\n",
    "        \n",
    "        # æ ·æœ¬æ•°ï¼ˆå…¨é‡è®­ç»ƒï¼‰\n",
    "        sample_size=None  # å–æ¶ˆé‡‡æ ·ï¼Œä½¿ç”¨å…¨é‡æ•°æ®\n",
    "    )\n",
    "\n",
    "# æ„å»ºè®­ç»ƒ/éªŒè¯é›†é…ç½®\n",
    "train_dataset_config = build_dataset_config(is_train=True)\n",
    "val_dataset_config = build_dataset_config(is_train=False)\n",
    "\n",
    "# ==================================================\n",
    "# 4. åˆå§‹åŒ–æ•°æ®é›†ï¼ˆä¸¥æ ¼åŒ¹é…SAMDatasetæ¥å£ï¼‰\n",
    "# ==================================================\n",
    "print(\"\\nğŸ“¥ åŠ è½½DRIVEè¡€ç®¡æ•°æ®é›†...\")\n",
    "# åˆå§‹åŒ–æ•°æ®é›†ï¼ˆç›´æ¥ä¼ å…¥Configå¯¹è±¡ï¼Œé€‚é…ä½ çš„SAMDatasetï¼‰\n",
    "train_dataset = SAMDataset(train_dataset_config)\n",
    "val_dataset = SAMDataset(val_dataset_config)\n",
    "\n",
    "print(f\"âœ… è®­ç»ƒé›†æ ·æœ¬æ•°: {len(train_dataset)}\")\n",
    "print(f\"âœ… éªŒè¯é›†æ ·æœ¬æ•°: {len(val_dataset)}\")\n",
    "\n",
    "# ==================================================\n",
    "# 5. åˆå§‹åŒ–TrainSAMè®­ç»ƒå™¨ï¼ˆä¸¥æ ¼åŒ¹é…ä½ çš„æ¥å£ï¼‰\n",
    "# ==================================================\n",
    "print(\"\\nğŸ”§ åˆå§‹åŒ–SAMè®­ç»ƒå™¨...\")\n",
    "trainer = TrainSAM(\n",
    "    config=finetune_config,\n",
    "    train_dataset=train_dataset,\n",
    "    val_dataset=val_dataset\n",
    ")\n",
    "\n",
    "# åˆ›å»ºè¾“å‡ºç›®å½•ï¼ˆå…¼å®¹TrainSAMå†…éƒ¨é€»è¾‘ï¼‰\n",
    "os.makedirs(trainer.output_dir, exist_ok=True)\n",
    "print(f\"ğŸ“Œ è®­ç»ƒç»“æœä¿å­˜è‡³: {trainer.output_dir}\")\n",
    "\n",
    "# ==================================================\n",
    "# 6. å¯åŠ¨SAMè®­ç»ƒï¼ˆè°ƒç”¨trainæ–¹æ³•ï¼‰\n",
    "# ==================================================\n",
    "print(\"\\nğŸš€ å¼€å§‹SAMå¾®è°ƒè®­ç»ƒï¼ˆåŸºäºYOLOè¡€ç®¡æ£€æµ‹æ¡†ï¼‰...\")\n",
    "trainer.train(num_epochs=finetune_config.num_epochs)\n",
    "\n",
    "# ==================================================\n",
    "# è®­ç»ƒå®Œæˆåè¾“å‡ºç»“æœ\n",
    "# ==================================================\n",
    "best_sam_ckpt = os.path.join(trainer.output_dir, 'best_model.pth')\n",
    "print(\"\\nğŸ‰ SAMè®­ç»ƒå®Œæˆï¼\")\n",
    "print(f\"âœ… æœ€ä¼˜éªŒè¯é›†Diceç³»æ•°: {trainer.best_val_dice:.4f}\")\n",
    "if os.path.exists(best_sam_ckpt):\n",
    "    print(f\"âœ… æœ€ä¼˜æ¨¡å‹æƒé‡: {best_sam_ckpt}\")\n",
    "else:\n",
    "    last_epoch_ckpt = os.path.join(trainer.output_dir, f'checkpoint_epoch_{finetune_config.num_epochs-1}.pth')\n",
    "    print(f\"âœ… æœ€åä¸€è½®æ¨¡å‹æƒé‡: {last_epoch_ckpt}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d4fb3eb-5e54-4977-8b1f-3108507d8f73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import cv2\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "# è·¯å¾„é…ç½®\n",
    "paths_to_add = [\n",
    "    '/root',         \n",
    "    '/root/task'   \n",
    "]\n",
    "for p in paths_to_add:\n",
    "    if p not in sys.path:\n",
    "        sys.path.append(p)\n",
    "\n",
    "# å¯¼å…¥æ ¸å¿ƒæ¨¡å—\n",
    "from utils.config import SAMFinetuneConfig\n",
    "from models.sam import SAMModel\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# ==================================================\n",
    "# 1. é…ç½®å‚æ•°ï¼ˆä»…æ”¹è¿™3ä¸ªè·¯å¾„ï¼ï¼‰\n",
    "# ==================================================\n",
    "IMG_PATH = \"../../../datasets/DRIVE/val/images/01_test.tif\"  # ä½ çš„å›¾ç‰‡è·¯å¾„\n",
    "SAM_CKPT = \"/root/task/src/YoloSAM/drive/runs/DRIVE-YOLO-SAM-VitB/run_0/best_model.pth\"\n",
    "YOLO_CKPT = \"/root/task/src/YoloSAM/drive/runs/yolo_vessel_detection2/weights/best.pt\"\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# ==================================================\n",
    "# 2. åŠ è½½æ¨¡å‹\n",
    "# ==================================================\n",
    "# åŠ è½½YOLO\n",
    "yolo_model = YOLO(YOLO_CKPT)\n",
    "yolo_model.to(DEVICE)\n",
    "print(f\"âœ… å·²åŠ è½½YOLOæ¨¡å‹: {YOLO_CKPT}\")\n",
    "\n",
    "# åŠ è½½SAM\n",
    "sam_config = SAMFinetuneConfig(\n",
    "    device=DEVICE,\n",
    "    model_type=\"vit_b\",\n",
    "    sam_path=\"/root/task/checkpoints/sam_vit_b_01ec64.pth\"\n",
    ")\n",
    "sam_model = SAMModel(sam_config)\n",
    "ckpt = torch.load(SAM_CKPT, map_location=DEVICE)\n",
    "sam_model.load_state_dict(ckpt['model_state_dict'])\n",
    "sam_model.to(DEVICE)\n",
    "sam_model.eval()\n",
    "print(f\"âœ… å·²åŠ è½½SAMæ¨¡å‹: {SAM_CKPT}\")\n",
    "\n",
    "# ==================================================\n",
    "# 3. å›¾ç‰‡åŠ è½½ï¼ˆå¼ºåˆ¶æ ‡å‡†åŒ–ï¼‰\n",
    "# ==================================================\n",
    "image = cv2.imread(IMG_PATH, cv2.IMREAD_COLOR)\n",
    "if image is None:\n",
    "    raise FileNotFoundError(f\"âŒ æ— æ³•åŠ è½½å›¾ç‰‡ï¼š{IMG_PATH}\")\n",
    "\n",
    "# å¼ºåˆ¶å›ºå®šå°ºå¯¸ï¼ˆDRIVEæ ‡å‡†ï¼‰\n",
    "TARGET_W, TARGET_H = 565, 584\n",
    "image = cv2.resize(image, (TARGET_W, TARGET_H), interpolation=cv2.INTER_LINEAR)\n",
    "print(f\"ğŸ“¸ å›¾ç‰‡å°ºå¯¸ï¼š{TARGET_W}x{TARGET_H}\")\n",
    "\n",
    "# é¢„å¤„ç†\n",
    "image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "image_sam = cv2.resize(image_rgb, (1024, 1024), interpolation=cv2.INTER_LINEAR)\n",
    "image_tensor = torch.from_numpy(image_sam).permute(2, 0, 1).float() / 255.0\n",
    "image_tensor = image_tensor.unsqueeze(0).to(DEVICE)\n",
    "\n",
    "# ==================================================\n",
    "# 4. YOLOæ£€æµ‹\n",
    "# ==================================================\n",
    "yolo_results = yolo_model.predict(\n",
    "    source=image,\n",
    "    conf=0.2,\n",
    "    iou=0.5,\n",
    "    imgsz=640,\n",
    "    device=DEVICE,\n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "boxes_list = []\n",
    "for r in yolo_results:\n",
    "    if r.boxes is not None:\n",
    "        boxes_list.extend(r.boxes.xyxy.cpu().numpy())\n",
    "\n",
    "if len(boxes_list) == 0:\n",
    "    raise ValueError(f\"âŒ æ— æ£€æµ‹æ¡†ï¼\")\n",
    "boxes = torch.tensor(np.array(boxes_list), device=DEVICE)\n",
    "print(f\"ğŸ” æ£€æµ‹åˆ°{len(boxes_list)}ä¸ªè¡€ç®¡æ¡†\")\n",
    "\n",
    "# ==================================================\n",
    "# 5. SAMåˆ†å‰² + åŠ¨æ€é€‚é…maskå°ºå¯¸ï¼ˆæ ¸å¿ƒä¿®å¤ï¼‰\n",
    "# ==================================================\n",
    "with torch.no_grad():\n",
    "    pred_mask, _ = sam_model.forward_one_image(\n",
    "        image=image_tensor,\n",
    "        bounding_box=boxes,\n",
    "        is_train=False\n",
    "    )\n",
    "\n",
    "# åŠ¨æ€å¤„ç†maskç»´åº¦ï¼ˆè§£å†³reshapeæŠ¥é”™ï¼‰\n",
    "pred_mask = torch.sigmoid(pred_mask).cpu().numpy()\n",
    "print(f\"ğŸ”§ SAMè¾“å‡ºmaskåŸå§‹å½¢çŠ¶ï¼š{pred_mask.shape}\")\n",
    "\n",
    "# æ–¹æ¡ˆ1ï¼šè‡ªåŠ¨å±•å¹³åå–å‰1024x1024ï¼ˆé€‚é…ä»»æ„ç»´åº¦ï¼‰\n",
    "pred_mask_flat = pred_mask.flatten()[:1024*1024]  # å–å‰1024*1024ä¸ªå…ƒç´ \n",
    "pred_mask_2d = pred_mask_flat.reshape(1024, 1024)  # è½¬ä¸º1024x1024\n",
    "\n",
    "# äºŒå€¼åŒ–\n",
    "pred_mask_bin = (pred_mask_2d > 0.5).astype(np.uint8)\n",
    "\n",
    "# ç¼©æ”¾è‡³ç›®æ ‡å°ºå¯¸ï¼ˆæ­¤æ—¶dsizeç»å¯¹æœ‰æ•ˆï¼‰\n",
    "pred_mask_final = cv2.resize(pred_mask_bin, (TARGET_W, TARGET_H), interpolation=cv2.INTER_NEAREST)\n",
    "print(f\"ğŸ”§ å¤„ç†åmaskå½¢çŠ¶ï¼š{pred_mask_final.shape}\")\n",
    "\n",
    "# ==================================================\n",
    "# 6. å¯è§†åŒ–ä¿å­˜\n",
    "# ==================================================\n",
    "vis_img = image.copy()\n",
    "\n",
    "# ç”»YOLOæ¡†\n",
    "for box in boxes_list:\n",
    "    x1, y1, x2, y2 = map(int, box)\n",
    "    cv2.rectangle(vis_img, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "\n",
    "# å åŠ åˆ†å‰²ç»“æœ\n",
    "vis_img[pred_mask_final == 1] = [0, 0, 255]\n",
    "\n",
    "# ä¿å­˜\n",
    "save_path = \"./vessel_segmentation_result.png\"\n",
    "cv2.imwrite(save_path, vis_img)\n",
    "\n",
    "print(f\"\\nğŸ‰ å¯è§†åŒ–å®Œæˆï¼\")\n",
    "print(f\"ğŸ“ ç»“æœä¿å­˜è‡³ï¼š{os.path.abspath(save_path)}\")\n",
    "print(f\"ğŸ“Œ æ•ˆæœè¯´æ˜ï¼š\")\n",
    "print(f\"   - ç»¿è‰²æ¡†ï¼šYOLOæ£€æµ‹çš„è¡€ç®¡ä½ç½®\")\n",
    "print(f\"   - çº¢è‰²åŒºåŸŸï¼šSAMåˆ†å‰²çš„è¡€ç®¡åŒºåŸŸ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff9b18ad-0006-4fd3-b273-cb4204f4e066",
   "metadata": {},
   "outputs": [],
   "source": [
    "# éšæœºè¯»å–1å¼ éªŒè¯é›†maskï¼ŒæŸ¥çœ‹åƒç´ åˆ†å¸ƒ\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "mask_path = \"../../../datasets/DRIVE/train/label/21_manual1.tif\"  # æ›¿æ¢ä¸ºä½ çš„maskè·¯å¾„\n",
    "mask = cv2.imread(mask_path, 0)\n",
    "print(f\"maskå°ºå¯¸ï¼š{mask.shape}\")\n",
    "print(f\"åƒç´ å€¼åˆ†å¸ƒï¼š0ï¼ˆèƒŒæ™¯ï¼‰={np.sum(mask==0)}, 1ï¼ˆè¡€ç®¡ï¼‰={np.sum(mask==255)}\")  # DRIVE maské€šå¸¸æ˜¯255=è¡€ç®¡\n",
    "print(f\"è¡€ç®¡å æ¯”ï¼š{np.sum(mask==255)/(mask.shape[0]*mask.shape[1]):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de07298b-dfc5-4988-aced-d2823f982ba2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
